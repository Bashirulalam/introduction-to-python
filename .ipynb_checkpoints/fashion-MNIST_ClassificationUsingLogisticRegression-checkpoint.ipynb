{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c92284c4-8420-48ad-b4af-eb19c0779887",
   "metadata": {},
   "source": [
    "# Fashion-MNIST Image Classification using Logistic Regression\n",
    "## Objective\n",
    "By the end of this project, we will:\n",
    "1. Understand how to load and explore the Fashion-MNIST dataset.\n",
    "2. Preprocess images for logistic regression.\n",
    "3. Train and evaluate a logistic regression classifier.\n",
    "4. Interpret the results and identify strengths/weaknesses.\n",
    "\n",
    "## Introduction to Fashion-MNIST dataset image Classification\n",
    "\n",
    "The Fashion-MNIST dataset is a widely used benchmark in machine learning and computer vision. It consists of 70,000 grayscale images of fashion items, such as t-shirts, trousers, and sneakers, each sized 28×28 pixels. The goal of Fashion-MNIST classification is to develop models that can accurately recognize and classify these images into their correct clothing categories.\n",
    "\n",
    "Because of its simplicity and well-structured format, Fashion-MNIST serves as an excellent starting point for learning image classification techniques, including logistic regression, neural networks, and deep learning models. Success on Fashion-MNIST demonstrates a model’s ability to extract meaningful features from image data and make accurate predictions on unseen samples.\n",
    "\n",
    "In this lab, we will use the logistic regression model for classification. Logistic regression is a simple yet powerful statistical method that predicts the probability of an input belonging to a particular class. For Fashion-MNIST, it models the probability that an image corresponds to each fashion category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd3aa5b-5d94-4ebc-80ea-17f943b38fae",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries\n",
    "We import essential libraries for this task:\n",
    "1. NumPy for numerical operations.\n",
    "2. Matplotlib for data visualization.\n",
    "3. scikit-learn for building and evaluating the logistic regression model. LogisticRegression from scikit-learn will be our classifier.\n",
    "4. classification_report & confusion_matrix help evaluate performance.\n",
    "5. TensorFlow to load the Fashion-MNIST dataset easily. We use Fashion-MNIST directly from Keras for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94860a7f-af99-4892-862d-2fafccdd4a7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.datasets import fashion_mnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb67fe-d948-4af1-af34-62d268a3283a",
   "metadata": {},
   "source": [
    "### Step 2: Load the MNIST dataset\n",
    "In this step, we load the Fashion-MNIST dataset using TensorFlow’s built-in tf.keras.datasets.fashion_mnist.load_data() function. This provides the dataset split into training and testing sets directly as NumPy arrays. Each image is a 28×28 grayscale pixel array, and the labels are integers from 0 to 9, each representing a specific clothing category. This built-in method is convenient and efficient for quick access to the dataset.\n",
    "\n",
    "1. Fashion-MNIST contains 28×28 grayscale images of 10 fashion categories.\n",
    "2. x_train has 60,000 images, x_test has 10,000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa7990-5816-4e25-bcb5-f2d0ff1dde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data: (x_train, y_train) for training, (x_test, y_test) for testing\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(\"Training set shape:\", x_train.shape)\n",
    "print(\"Test set shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb713204-22cb-4727-9d67-6b07103a6d8b",
   "metadata": {},
   "source": [
    "### Step 3: Visualize sample images\n",
    "Here we display five images from the training set. This visualization helps familiarize  with the dataset and confirms that the images and labels align."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a1065-b3bd-4ce1-9dbb-9c1639afb1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ecc8d-f793-4877-bef8-e61fc1e096d0",
   "metadata": {},
   "source": [
    "### Visualization of the class distribution of the dataset\n",
    "Our Fashion-MNIST dataset is well balanced with 7000 images of each ctaegorys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a7a3f7-3162-4058-835b-d02bea597b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Combine training and test labels for overall distribution\n",
    "all_labels = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Count occurrences of each class\n",
    "unique, counts = np.unique(all_labels, return_counts=True)\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(unique, counts, tick_label=unique)\n",
    "plt.title(\"Class Distribution in Fashion-MNIST Dataset\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520ecd96-d87f-4a89-b9d3-9c9e2ad8c9ef",
   "metadata": {},
   "source": [
    "### Step 4: Preprocess the data\n",
    "Since logistic regression expects input as feature vectors, each 28×28 image must be flattened into a one-dimensional vector of length 784 (28 × 28).\n",
    "\n",
    "We also normalize the pixel values from the range 0–255 to 0–1. Normalization improves model performance and helps achieve faster and more stable convergence during training.\n",
    "\n",
    "1. Flattening: Converts each 28×28 image into a 1D vector of size 784.\n",
    "2. Normalization: Scales pixel values to the range [0, 1] for better model convergence and stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87812a3b-3897-4ff2-a076-e4fb1c6033cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each 28x28 image into a 784-length vector\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "x_train_flat = x_train_flat.astype('float32') / 255.0\n",
    "x_test_flat = x_test_flat.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8bdcac-17c3-4885-8b4d-ef624e40ee80",
   "metadata": {},
   "source": [
    "### Step 4.1: Displaying the pixel matrix of an image\n",
    "Now we will select an image and display the pixel matrix of that image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb86198e-1e65-4537-b8a5-cec5d5cff0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one image\n",
    "image = x_train[0]\n",
    "\n",
    "# Display the pixel matrix\n",
    "print(\"Pixel matrix for the first image:\")\n",
    "print(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa9c35-5bee-46f8-82a4-3d20491623c3",
   "metadata": {},
   "source": [
    "### Step 5: Build and Train the logistic regression model\n",
    "We create a multinomial logistic regression model using the ‘saga’ solver, which is suitable for multi-class classification problems and large datasets. The model is then trained on the flattened and normalized Fashion-MNIST images along with their corresponding labels.\n",
    "\n",
    "1. Multinomial logistic regression: Handles multiple classes (10 fashion categories in Fashion-MNIST).\n",
    "2. SAGA solver: Efficient for large datasets and supports the multinomial loss function.\n",
    "3. Training process: The model learns weights for each pixel to distinguish between different clothing categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e71fe98-c582-45f2-a22d-aa60ac24c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 'saga' solver for large datasets and multinomial classification\n",
    "model = LogisticRegression(\n",
    "    solver='saga',\n",
    "    multi_class='multinomial',\n",
    "    max_iter=3000,\n",
    "    tol=0.01, \n",
    "    verbose=1,        \n",
    "    n_jobs=-1,        \n",
    "    warm_start=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2aaa64-ce1a-4c7f-a52b-61e22978641d",
   "metadata": {},
   "source": [
    "### Step 6: Evaluate the model\n",
    "After training, we predict labels for the test dataset. We evaluate the model’s performance using accuracy and detailed classification metrics such as precision, recall, and F1-score.\n",
    "1. Accuracy gives an overall measure of correct predictions.\n",
    "2. Confusion matrix shows per-class performance.\n",
    "3. Classification report gives precision, recall, and F1 score for each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0bb457-aac5-4f54-9ae6-3b63df892256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on the test set\n",
    "accuracy = model.score(x_test_flat, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predictions for detailed evaluation\n",
    "y_pred = model.predict(x_test_flat)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dc54ec-2c19-4a47-aa37-2b8f5c4e12b6",
   "metadata": {},
   "source": [
    "### Step 7: Visualize the predictions\n",
    "This step visualizes the first 10 images from the test set where the model predicted the digit correctly. It helps you qualitatively assess the model’s successes. Here we also display the first 10 test images where the model made incorrect predictions, highlighting areas where the model could be improved. Visualisation helps you better understand and interpret your results and model performance.\n",
    "1. np.where(y_pred == y_test) gets the indices where predictions match the true labels.\n",
    "2. np.where(y_pred != y_test) gets the indices where they differ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8a1c4-d35b-42eb-abe6-7e77e86fb75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_test[i], cmap='gray')\n",
    "    plt.title(f\"Pred: {y_pred[i]}\\nTrue: {y_test[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8cdaf-c027-43cb-b74e-999ca19025ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices of correct and incorrect predictions\n",
    "correct_indices = np.where(y_pred == y_test)[0]\n",
    "incorrect_indices = np.where(y_pred != y_test)[0]\n",
    "\n",
    "# Visualize first 10 correct predictions\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, idx in enumerate(correct_indices[:10]):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_test[idx], cmap='gray')\n",
    "    plt.title(f\"Pred: {y_pred[idx]}\\nTrue: {y_test[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Correct Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e269ac-ff0a-44e1-a605-d59a8fa64c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first 10 incorrect predictions\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, idx in enumerate(incorrect_indices[:10]):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_test[idx], cmap='gray')\n",
    "    plt.title(f\"Pred: {y_pred[idx]}\\nTrue: {y_test[idx]}\", color='red')\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Incorrect Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a1a677-abe9-4a58-8b0a-f3db749cee85",
   "metadata": {},
   "source": [
    "### Model output analysis\n",
    "\n",
    "1. Logistic regression performs well on visually distinct classes like Trouser, Sneaker, Bag, achieving high precision, recall, and F1-scores.\n",
    "2. The model struggles with visually similar top-wear items such as T-shirt, Pullover, Shirt, and Coat, leading to more misclassifications.\n",
    "3. Despite these limitations, the overall accuracy of ~84.5% shows that the model captures general patterns in the data and serves as a reasonable     baseline.\n",
    "4. Decision: Logistic regression is sufficient for initial experiments or fast baseline evaluation, but for higher accuracy on similar fashion items,   more advanced models like CNNs or feature engineering are recommended.\n",
    "5. The model’s macro F1-score of 0.84 indicates balanced performance across classes, but targeted improvements are needed for challenging categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f8bcfd-2940-4e54-a708-37781739885c",
   "metadata": {},
   "source": [
    "## Regularization in Logistic Regression\n",
    "\n",
    "### L1 and L2 regularization in logistic regression\n",
    "In logistic regression, L1 regularization is a penalty added to the loss function that encourages sparsity in the model’s weights. It adds the sum of the absolute values of the coefficients to the loss. L1 regularization penalizes large weights, which can help with feature selection and prevent overfitting.\n",
    "\n",
    "In logistic regression, L2 regularization is a penalty added to the loss function that discourages large weights. It adds the sum of the squared values of the coefficients to the loss. L2 regularization shrinks the weights gradually, which helps prevent overfitting and improves the model’s generalization.\n",
    "\n",
    "### Applied regularization in our model.\n",
    "\n",
    "In our current Fashion-MNIST logistic regression setup, we did not explicitly apply regularization. The default LogisticRegression in scikit-learn uses L2 regularization with C=1.0.\n",
    "\n",
    "So technically, some L2 regularization is applied by default, but we did not tune the strength (C) or switch to L1. That’s why the results we observed are from a baseline model with default regularization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d6ce94-48d3-48eb-b1ab-242cf25cb2f0",
   "metadata": {},
   "source": [
    "## Saving and Using the Trained Model\n",
    "\n",
    "After training our logistic regression model on the Fashion-MNIST dataset, ywe can save it to disk using Python’s joblib library. Saving the model allows to reuse it later without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb9e7c-d9f2-4503-a86e-c88caee8b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# 1. Save the model\n",
    "joblib.dump(model, 'fashion_mnist_logreg_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66abb742-3c7a-42c3-a7b3-ca74ab4096e4",
   "metadata": {},
   "source": [
    "Now we can call 'fashion_mnist_logreg_model.pk1' to make predictions on unseen, new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b84f8db-b668-48b8-9d63-d712751592f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the model\n",
    "loaded_model = joblib.load('fashion_mnist_logreg_model.pkl')\n",
    "\n",
    "# 3. Predict on a new sample (example: first test image)\n",
    "# Flatten and normalize the image\n",
    "new_image = x_test[0].reshape(1, -1) / 255.0\n",
    "predicted_class = loaded_model.predict(new_image)\n",
    "\n",
    "print(\"Predicted class:\", predicted_class[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90bccfe-5156-41e4-92e7-c23d843b02f2",
   "metadata": {},
   "source": [
    "We use our saved model to predict a new image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
